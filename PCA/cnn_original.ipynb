{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning and training a Convolutional Neural Network for Intrusion Detection\n",
    "The CNN model will return a value between 0 and 1, which is the probability of the input flow of being malicious. \n",
    "You will select a range of hyperparameters to tune the CNN using Random search and you will train it on a dataset of benign traffic and DDoS attack traffic.\n",
    "\n",
    "The network traffic has been previously pre-processed in a way that packets are grouped in bi-directional traffic flows using the 5-tuple (source IP, destination IP, source Port, destination Port, protocol). Each flow is represented as a 100x20 array, where the rows are the packets of the flow in chronological order, while each column is a packet-level feature in the following order:\n",
    "\n",
    "| Feature nr.         | Feature Name |\n",
    "|---------------------|---------------------|\n",
    "| 00 | timestamp (IAT) | \n",
    "| 01 | packet_length (bytes)| \n",
    "| 02 | IP_flags_df (0/1) |\n",
    "| 03 | IP_flags_mf (0/1) |\n",
    "| 04 | IP_flags_rb (0/1) | \n",
    "| 05 | IP_frag_off (0/1) |\n",
    "| 06 | protocols (integer) |\n",
    "| 07 | TCP_length (bytes) |\n",
    "| 08 | TCP_flags_ack (0/1) |\n",
    "| 09 | TCP_flags_cwr (0/1) |\n",
    "| 10 | TCP_flags_ece (0/1) |\n",
    "| 11 | TCP_flags_fin (0/1) |\n",
    "| 12 | TCP_flags_push (0/1) |\n",
    "| 13 | TCP_flags_res (0/1) |\n",
    "| 14 | TCP_flags_reset (0/1) |\n",
    "| 15 | TCP_flags_syn (0/1) |\n",
    "| 16 | TCP_flags_urg (0/1) |\n",
    "| 17 | TCP_window_size (bytes) |\n",
    "| 18 | UDP_length (bytes) |\n",
    "| 19 | ICMP_type (code) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset_PCA-val.hdf5', 'Dataset_PCA-train.hdf5', 'Dataset_PCA-test.hdf5']\n",
      "(1446, 2, 2, 1) (1446,)\n",
      "(179, 2, 2, 1) (179,)\n",
      "(161, 2, 2, 1) (161,)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, GlobalMaxPooling2D, Flatten,MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam,SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from keras.regularizers import l1,l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from util_functions import *\n",
    "\n",
    "# disable GPUs for test reproducibility\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# print(os.listdir('./Dataset/'))\n",
    "print(os.listdir('./Reshaped_Dataset/'))\n",
    "\n",
    "SEED=0\n",
    "\n",
    "# DATASET_FOLDER = \"./Dataset\"\n",
    "DATASET_FOLDER = \"./Reshaped_Dataset\"\n",
    "# DATASET_FOLDER = \"./Traffic_Manipulator_test/Manipulated_Dataset\"\n",
    "\n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5',channels=True)\n",
    "X_val, y_val = load_dataset(DATASET_FOLDER + \"/*\" + '-val.hdf5',channels=True)\n",
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5',channels=True)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileModel(model,optimizer='sgd', lr=0.001):\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr, momentum=0.0)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "The following method defines the CNN model with configurable hyperparameters. Each hyperparameter has a default value that can be set during the tuning process. In the following cell, your task is to finalise the model by adding a **GlobalMaxPooling2D** layer, a **Flatten** layer and a final **Dense** layer with Sigmoid activation function for binary classification. Additional, you may want to add **Dropout** regularisation to your model.\n",
    "\n",
    "You may notice that the **Convolutional** layer (Conv2D) has fixed hyperparameters' values (number of filters, kernel size, etc.). Change the code in a way that Conv2D can use the values listed in the definition of the *create_model* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the CNN model\n",
    "def create_model(optimizer='adam', filters = 100, kernel_size=(3,3), strides=(1,1), padding='same',learning_rate = 0.001,dropout_rate=0.1):\n",
    "    cnn_model = Sequential(name  = \"cnn\")\n",
    "    cnn_model.add(Conv2D(filters=filters, kernel_size=(3, X_train.shape[2]), input_shape=X_train.shape[1:], data_format='channels_last', activation='relu', padding=padding, strides=strides))\n",
    "    cnn_model.add(Dropout(dropout_rate))\n",
    "    cnn_model.add(GlobalMaxPooling2D())\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    compileModel(cnn_model, optimizer,learning_rate)\n",
    "    print (cnn_model.summary())\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search\n",
    "The code in the following cell implements *random search* to tune the hyperparameters of the CNN model. \n",
    "\n",
    "In the cell below, add the relevant hyperparameters for the CNN to the **param_dist** dictionary. The tunable hyperparameters are those available in definition of the *create_model* above. Remember to use the *uniform* method for generating floating point values (e.g., for the **learning_rate**), use *randint* for generating the integer hyperparameters (e.g., the **number of filters**), while use lists for multi-dimensional hyperparameters (e.g., **kernel_size**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25240/424657782.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 55)          385       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 2, 2, 55)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_15 (Gl  (None, 55)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 55)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 53ms/step - loss: 0.6082 - accuracy: 0.5021 - val_loss: 0.5819 - val_accuracy: 0.5280\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5636 - accuracy: 0.5104 - val_loss: 0.5422 - val_accuracy: 0.5528\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5211 - accuracy: 0.7663 - val_loss: 0.5072 - val_accuracy: 0.9752\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4849 - accuracy: 0.9779 - val_loss: 0.4757 - val_accuracy: 0.9876\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.9917 - val_loss: 0.4471 - val_accuracy: 0.9938\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.9945 - val_loss: 0.4208 - val_accuracy: 0.9938\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.9945 - val_loss: 0.3957 - val_accuracy: 0.9938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.9945 - val_loss: 0.3713 - val_accuracy: 0.9938\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.9945 - val_loss: 0.3475 - val_accuracy: 0.9938\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3263 - accuracy: 0.9945 - val_loss: 0.3256 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3064 - accuracy: 0.9945 - val_loss: 0.3050 - val_accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2872 - accuracy: 0.9945 - val_loss: 0.2855 - val_accuracy: 0.9938\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.9945 - val_loss: 0.2667 - val_accuracy: 0.9938\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2505 - accuracy: 0.9945 - val_loss: 0.2491 - val_accuracy: 0.9938\n",
      "Epoch 15/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2434 - accuracy: 0.9900Restoring model weights from the end of the best epoch: 5.\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2384 - accuracy: 0.9945 - val_loss: 0.2326 - val_accuracy: 0.9938\n",
      "Epoch 00015: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.9295\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 2, 2, 55)          385       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 2, 2, 55)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_16 (Gl  (None, 55)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 55)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 0.6831 - accuracy: 0.4910 - val_loss: 0.6218 - val_accuracy: 0.5280\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.5408 - val_loss: 0.5838 - val_accuracy: 0.6087\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5867 - accuracy: 0.8119 - val_loss: 0.5518 - val_accuracy: 0.9876\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5495 - accuracy: 0.9267 - val_loss: 0.5235 - val_accuracy: 0.9938\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.9364 - val_loss: 0.4969 - val_accuracy: 0.9938\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.9405 - val_loss: 0.4716 - val_accuracy: 0.9938\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.9391 - val_loss: 0.4457 - val_accuracy: 0.9938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.9405 - val_loss: 0.4225 - val_accuracy: 0.9938\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.9378 - val_loss: 0.4009 - val_accuracy: 0.9938\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4100 - accuracy: 0.9419 - val_loss: 0.3848 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3889 - accuracy: 0.9405 - val_loss: 0.3673 - val_accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 0.9405 - val_loss: 0.3511 - val_accuracy: 0.9938\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.9419 - val_loss: 0.3369 - val_accuracy: 0.9938\n",
      "Epoch 14/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3591 - accuracy: 0.9400Restoring model weights from the end of the best epoch: 4.\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.9433 - val_loss: 0.3247 - val_accuracy: 0.9938\n",
      "Epoch 00014: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.9917\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 2, 2, 39)          273       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 2, 2, 39)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_17 (Gl  (None, 39)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 39)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313\n",
      "Trainable params: 313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 0.7493 - accuracy: 0.1535 - val_loss: 0.7383 - val_accuracy: 0.0559\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7358 - accuracy: 0.1992 - val_loss: 0.7259 - val_accuracy: 0.0559\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7192 - accuracy: 0.2725 - val_loss: 0.7142 - val_accuracy: 0.4099\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7099 - accuracy: 0.3665 - val_loss: 0.7029 - val_accuracy: 0.5404\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.4232 - val_loss: 0.6924 - val_accuracy: 0.5466\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6797 - accuracy: 0.4703 - val_loss: 0.6823 - val_accuracy: 0.5466\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6741 - accuracy: 0.4896 - val_loss: 0.6726 - val_accuracy: 0.5528\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6635 - accuracy: 0.5408 - val_loss: 0.6633 - val_accuracy: 0.5901\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6559 - accuracy: 0.5920 - val_loss: 0.6544 - val_accuracy: 0.6770\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6439 - accuracy: 0.6694 - val_loss: 0.6457 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.7095 - val_loss: 0.6373 - val_accuracy: 0.7826\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6251 - accuracy: 0.7828 - val_loss: 0.6290 - val_accuracy: 0.8882\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.8603 - val_loss: 0.6211 - val_accuracy: 0.9689\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6060 - accuracy: 0.9156 - val_loss: 0.6135 - val_accuracy: 0.9814\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.9212 - val_loss: 0.6060 - val_accuracy: 0.9938\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5963 - accuracy: 0.9336 - val_loss: 0.5986 - val_accuracy: 0.9938\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5819 - accuracy: 0.9585 - val_loss: 0.5914 - val_accuracy: 0.9938\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5755 - accuracy: 0.9599 - val_loss: 0.5845 - val_accuracy: 0.9938\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.9820 - val_loss: 0.5778 - val_accuracy: 0.9938\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5641 - accuracy: 0.9779 - val_loss: 0.5711 - val_accuracy: 0.9938\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5541 - accuracy: 0.9834 - val_loss: 0.5645 - val_accuracy: 0.9938\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5475 - accuracy: 0.9876 - val_loss: 0.5580 - val_accuracy: 0.9938\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.9834 - val_loss: 0.5516 - val_accuracy: 0.9938\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5319 - accuracy: 0.9889 - val_loss: 0.5453 - val_accuracy: 0.9938\n",
      "Epoch 25/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5445 - accuracy: 0.9800Restoring model weights from the end of the best epoch: 15.\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5257 - accuracy: 0.9903 - val_loss: 0.5390 - val_accuracy: 0.9938\n",
      "Epoch 00025: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.9212\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 2, 2, 39)          273       \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 2, 2, 39)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_18 (Gl  (None, 39)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 39)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313\n",
      "Trainable params: 313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 0.7440 - accuracy: 0.3790 - val_loss: 0.7494 - val_accuracy: 0.4224\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7173 - accuracy: 0.3914 - val_loss: 0.7323 - val_accuracy: 0.4037\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6984 - accuracy: 0.4094 - val_loss: 0.7166 - val_accuracy: 0.2981\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.4661 - val_loss: 0.7025 - val_accuracy: 0.2484\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.5145 - val_loss: 0.6894 - val_accuracy: 0.5031\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6667 - accuracy: 0.5768 - val_loss: 0.6773 - val_accuracy: 0.6211\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6579 - accuracy: 0.6432 - val_loss: 0.6660 - val_accuracy: 0.7329\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6404 - accuracy: 0.6888 - val_loss: 0.6552 - val_accuracy: 0.8012\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6381 - accuracy: 0.6985 - val_loss: 0.6449 - val_accuracy: 0.8509\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6320 - accuracy: 0.7261 - val_loss: 0.6352 - val_accuracy: 0.8634\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.7676 - val_loss: 0.6263 - val_accuracy: 0.8820\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6157 - accuracy: 0.7967 - val_loss: 0.6171 - val_accuracy: 0.8820\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6039 - accuracy: 0.8492 - val_loss: 0.6092 - val_accuracy: 0.9689\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.8686 - val_loss: 0.6014 - val_accuracy: 0.9752\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5888 - accuracy: 0.8907 - val_loss: 0.5941 - val_accuracy: 0.9814\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.8921 - val_loss: 0.5868 - val_accuracy: 0.9814\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.9101 - val_loss: 0.5798 - val_accuracy: 0.9814\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5687 - accuracy: 0.9225 - val_loss: 0.5733 - val_accuracy: 0.9876\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5675 - accuracy: 0.9073 - val_loss: 0.5664 - val_accuracy: 0.9876\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5668 - accuracy: 0.9170 - val_loss: 0.5599 - val_accuracy: 0.9876\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5550 - accuracy: 0.9212 - val_loss: 0.5533 - val_accuracy: 0.9814\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5463 - accuracy: 0.9253 - val_loss: 0.5470 - val_accuracy: 0.9814\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5426 - accuracy: 0.9322 - val_loss: 0.5408 - val_accuracy: 0.9876\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.9184 - val_loss: 0.5349 - val_accuracy: 0.9876\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.9253 - val_loss: 0.5291 - val_accuracy: 0.9938\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5297 - accuracy: 0.9225 - val_loss: 0.5233 - val_accuracy: 0.9938\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.9239 - val_loss: 0.5176 - val_accuracy: 0.9938\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5148 - accuracy: 0.9281 - val_loss: 0.5118 - val_accuracy: 0.9938\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5154 - accuracy: 0.9225 - val_loss: 0.5068 - val_accuracy: 0.9938\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5061 - accuracy: 0.9322 - val_loss: 0.5020 - val_accuracy: 0.9938\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.9281 - val_loss: 0.4971 - val_accuracy: 0.9938\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4956 - accuracy: 0.9198 - val_loss: 0.4922 - val_accuracy: 0.9938\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4970 - accuracy: 0.9295 - val_loss: 0.4878 - val_accuracy: 0.9938\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.9253 - val_loss: 0.4830 - val_accuracy: 0.9938\n",
      "Epoch 35/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4676 - accuracy: 0.9800Restoring model weights from the end of the best epoch: 25.\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4795 - accuracy: 0.9322 - val_loss: 0.4783 - val_accuracy: 0.9938\n",
      "Epoch 00035: early stopping\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.9959\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_23 (Conv2D)          (None, 2, 2, 17)          119       \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 2, 2, 17)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_19 (Gl  (None, 17)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 17)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137\n",
      "Trainable params: 137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 0.6587 - accuracy: 0.5491 - val_loss: 0.6435 - val_accuracy: 0.5093\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.6902 - val_loss: 0.6148 - val_accuracy: 0.9068\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5892 - accuracy: 0.9073 - val_loss: 0.5912 - val_accuracy: 0.9938\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.9557 - val_loss: 0.5709 - val_accuracy: 0.9938\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.9654 - val_loss: 0.5541 - val_accuracy: 0.9938\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.9710 - val_loss: 0.5389 - val_accuracy: 0.9938\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.9710 - val_loss: 0.5244 - val_accuracy: 0.9938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.9723 - val_loss: 0.5102 - val_accuracy: 0.9938\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.9737 - val_loss: 0.4965 - val_accuracy: 0.9938\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.9779 - val_loss: 0.4833 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.9696 - val_loss: 0.4706 - val_accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.9737 - val_loss: 0.4581 - val_accuracy: 0.9938\n",
      "Epoch 13/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4236 - accuracy: 0.9500Restoring model weights from the end of the best epoch: 3.\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4270 - accuracy: 0.9723 - val_loss: 0.4459 - val_accuracy: 0.9938\n",
      "Epoch 00013: early stopping\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.9308\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 2, 2, 17)          119       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 2, 2, 17)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_20 (Gl  (None, 17)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 17)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137\n",
      "Trainable params: 137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 0.7522 - accuracy: 0.5325 - val_loss: 0.7238 - val_accuracy: 0.4969\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.6100 - val_loss: 0.6625 - val_accuracy: 0.8882\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6262 - accuracy: 0.8022 - val_loss: 0.6170 - val_accuracy: 0.9068\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5920 - accuracy: 0.8520 - val_loss: 0.5822 - val_accuracy: 0.9068\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5651 - accuracy: 0.8534 - val_loss: 0.5550 - val_accuracy: 0.9752\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5431 - accuracy: 0.9129 - val_loss: 0.5320 - val_accuracy: 0.9938\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.9156 - val_loss: 0.5109 - val_accuracy: 0.9938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.9308 - val_loss: 0.4925 - val_accuracy: 0.9938\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.9281 - val_loss: 0.4756 - val_accuracy: 0.9938\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.9364 - val_loss: 0.4590 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4563 - accuracy: 0.9281 - val_loss: 0.4441 - val_accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.9336 - val_loss: 0.4293 - val_accuracy: 0.9938\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.9295 - val_loss: 0.4154 - val_accuracy: 0.9938\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.9336 - val_loss: 0.4021 - val_accuracy: 0.9938\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.9364 - val_loss: 0.3903 - val_accuracy: 0.9938\n",
      "Epoch 16/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3976 - accuracy: 0.9500Restoring model weights from the end of the best epoch: 6.\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.9322 - val_loss: 0.3785 - val_accuracy: 0.9876\n",
      "Epoch 00016: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.9931\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 1, 1, 33)          231       \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 1, 1, 33)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_21 (Gl  (None, 33)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 33)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 25ms/step - loss: 0.7873 - accuracy: 0.1355 - val_loss: 0.7305 - val_accuracy: 0.1180\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7098 - accuracy: 0.2780 - val_loss: 0.6644 - val_accuracy: 0.6087\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6456 - accuracy: 0.7510 - val_loss: 0.6072 - val_accuracy: 0.9938\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5878 - accuracy: 0.9308 - val_loss: 0.5622 - val_accuracy: 0.9938\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5479 - accuracy: 0.9668 - val_loss: 0.5252 - val_accuracy: 0.9938\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.9765 - val_loss: 0.4925 - val_accuracy: 0.9814\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.9599 - val_loss: 0.4641 - val_accuracy: 0.9068\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.9308 - val_loss: 0.4393 - val_accuracy: 0.9068\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.9322 - val_loss: 0.4168 - val_accuracy: 0.9068\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.9267 - val_loss: 0.3964 - val_accuracy: 0.9068\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.9281 - val_loss: 0.3778 - val_accuracy: 0.9068\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.9253 - val_loss: 0.3610 - val_accuracy: 0.9068\n",
      "Epoch 13/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3606 - accuracy: 0.9600Restoring model weights from the end of the best epoch: 3.\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3540 - accuracy: 0.9198 - val_loss: 0.3452 - val_accuracy: 0.9068\n",
      "Epoch 00013: early stopping\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.9308\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 1, 1, 33)          231       \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 1, 1, 33)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_22 (Gl  (None, 33)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 33)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 0.8090 - accuracy: 0.1729 - val_loss: 0.7724 - val_accuracy: 0.0932\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7457 - accuracy: 0.3140 - val_loss: 0.7074 - val_accuracy: 0.4099\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.4813 - val_loss: 0.6538 - val_accuracy: 0.7267\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.7248 - val_loss: 0.6086 - val_accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.8893 - val_loss: 0.5691 - val_accuracy: 0.9814\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5678 - accuracy: 0.9198 - val_loss: 0.5344 - val_accuracy: 0.9876\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.9405 - val_loss: 0.5024 - val_accuracy: 0.9938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.9267 - val_loss: 0.4732 - val_accuracy: 0.9938\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.9184 - val_loss: 0.4483 - val_accuracy: 0.9814\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.9046 - val_loss: 0.4257 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8963 - val_loss: 0.4040 - val_accuracy: 0.9130\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8852 - val_loss: 0.3839 - val_accuracy: 0.9068\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4014 - accuracy: 0.8866 - val_loss: 0.3674 - val_accuracy: 0.9317\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8907 - val_loss: 0.3500 - val_accuracy: 0.9317\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8963 - val_loss: 0.3350 - val_accuracy: 0.9317\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8935 - val_loss: 0.3217 - val_accuracy: 0.9317\n",
      "Epoch 17/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3937 - accuracy: 0.8500Restoring model weights from the end of the best epoch: 7.\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3401 - accuracy: 0.8949 - val_loss: 0.3071 - val_accuracy: 0.9317\n",
      "Epoch 00017: early stopping\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.9931\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 2, 2, 17)          119       \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 2, 2, 17)          0         \n",
      "                                                                 \n",
      " global_max_pooling2d_23 (Gl  (None, 17)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 17)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137\n",
      "Trainable params: 137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "2 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 232, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"/tmp/ipykernel_25240/1646492150.py\", line 4, in create_model\n",
      "    cnn_model.add(Conv2D(filters=filters, kernel_size=(3, X_train.shape[2]), input_shape=X_train.shape[1:], data_format='channels_last', activation='relu', padding=padding, strides=strides))\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 530, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1939, in _create_c_op\n",
      "    raise ValueError(e.message)\n",
      "ValueError: Exception encountered when calling layer \"conv2d_17\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_17/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_17/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,1], [3,2,1,60].\n",
      "\n",
      "Call arguments received:\n",
      "  • inputs=tf.Tensor(shape=(None, 2, 2, 1), dtype=float32)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 232, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"/tmp/ipykernel_25240/1646492150.py\", line 4, in create_model\n",
      "    cnn_model.add(Conv2D(filters=filters, kernel_size=(3, X_train.shape[2]), input_shape=X_train.shape[1:], data_format='channels_last', activation='relu', padding=padding, strides=strides))\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 530, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1939, in _create_c_op\n",
      "    raise ValueError(e.message)\n",
      "ValueError: Exception encountered when calling layer \"conv2d_18\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_18/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_18/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,1], [3,2,1,60].\n",
      "\n",
      "Call arguments received:\n",
      "  • inputs=tf.Tensor(shape=(None, 2, 2, 1), dtype=float32)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/alessia/miniconda3/envs/NIADML/lib/python3.9/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.96058092 0.95850623 0.96196404 0.96196404]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 14ms/step - loss: 0.7104 - accuracy: 0.4039 - val_loss: 0.6497 - val_accuracy: 0.5901\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.5961 - val_loss: 0.6040 - val_accuracy: 0.9006\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.8658 - val_loss: 0.5658 - val_accuracy: 0.9752\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.9302 - val_loss: 0.5327 - val_accuracy: 0.9814\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.9405 - val_loss: 0.5014 - val_accuracy: 0.9814\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.9523 - val_loss: 0.4704 - val_accuracy: 0.9876\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.9606 - val_loss: 0.4415 - val_accuracy: 0.9876\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.9606 - val_loss: 0.4138 - val_accuracy: 0.9938\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.9585 - val_loss: 0.3873 - val_accuracy: 0.9938\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.9599 - val_loss: 0.3643 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.9633 - val_loss: 0.3396 - val_accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.9620 - val_loss: 0.3142 - val_accuracy: 0.9938\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.9627 - val_loss: 0.2914 - val_accuracy: 0.9938\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3048 - accuracy: 0.9633 - val_loss: 0.2717 - val_accuracy: 0.9938\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.9661 - val_loss: 0.2534 - val_accuracy: 0.9938\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.9682 - val_loss: 0.2343 - val_accuracy: 0.9938\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9675 - val_loss: 0.2204 - val_accuracy: 0.9938\n",
      "Epoch 18/100\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2599 - accuracy: 0.9600Restoring model weights from the end of the best epoch: 8.\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2410 - accuracy: 0.9668 - val_loss: 0.2076 - val_accuracy: 0.9938\n",
      "Epoch 00018: early stopping\n",
      "Total training time (sec):  17.540448904037476\n",
      "Best parameters found:  {'filters': 17, 'kernel_size': (2, 3), 'learning_rate': 0.0009121687287754933, 'padding': 'same', 'strides': (1, 1)}\n",
      "Best cross-validated accuracy: 0.96\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.9944\n",
      "F1 score of the best model: 0.99\n",
      "Test accuracy of the best model: 0.99\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "k=2 # number of folds for cross-validation\n",
    "PATIENCE = 10\n",
    "\n",
    "# Create a KerasClassifier based on the create_model function\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n",
    "\n",
    "# Define the hyperparameters to tune and their possible values\n",
    "param_dist = {\n",
    "    'learning_rate' : uniform(0.0001, 0.001),\n",
    "    'filters' : randint(16,64),\n",
    "    'kernel_size': [(2,2),(3,3),(2,3)],\n",
    "    'strides': [(1,1),(2,2)],\n",
    "    'padding' : ['same', 'valid']\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=5, cv=k, random_state=SEED)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=PATIENCE, restore_best_weights=True)\n",
    "start_time = time.time()\n",
    "random_search_result = random_search.fit(X_train, y_train,epochs=100, validation_data=(X_val, y_val),callbacks= [ early_stopping])\n",
    "stop_time = time.time()\n",
    "\n",
    "# Total training time\n",
    "print(\"Total training time (sec): \", stop_time-start_time)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters found: \", random_search_result.best_params_)\n",
    "print(\"Best cross-validated accuracy: {:.2f}\".format(random_search_result.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "# F1 score on the best model on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score of the best model: {:.2f}\".format(f1))\n",
    "print(\"Test accuracy of the best model: {:.2f}\".format(test_accuracy))\n",
    "# Print the false positives and false negatives\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results in a log file\n",
    "with open(\"random_search_log.txt\", \"a\") as f:\n",
    "    f.write(\"Shape of the train dataset: {}\\n\".format(X_train.shape)) \n",
    "    f.write(\"Shape of the test dataset: {}\\n\".format(X_test.shape)) \n",
    "    f.write(\"Shape of the validation dataset: {}\\n\".format(X_val.shape)) \n",
    "    f.write(\"Best parameters found: {}\\n\".format(random_search_result.best_params_))\n",
    "    f.write(\"Best cross-validated accuracy: {:.2f}\\n\".format(random_search_result.best_score_))\n",
    "    f.write(\"F1 score of the best model: {:.2f}\\n\".format(f1))\n",
    "    f.write(\"Test accuracy of the best model: {:.2f}\\n\".format(test_accuracy))\n",
    "    f.write(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Reduce the dataset for simplicity\n",
    "X_train_reduced = X_train.reshape(X_train.shape[0], -1)[:1000]\n",
    "y_train_reduced = y_train[:1000]\n",
    "X_test_reduced = X_test.reshape(X_test.shape[0], -1)[:200]\n",
    "y_test_reduced = y_test[:200]\n",
    "\n",
    "# Create and train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=SEED)\n",
    "svm_model.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test_reduced)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_reduced, y_pred_svm)\n",
    "print(f\"SVM Test Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NIADML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
