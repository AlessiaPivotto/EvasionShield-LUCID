{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from keras.regularizers import l1,l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from util_functions import *\n",
    "\n",
    "# disable GPUs for test reproducibility\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "SEED=0\n",
    "\n",
    "DATASET_FOLDER = \"./DOS2019_Binary\"\n",
    "\n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5')\n",
    "X_val, y_val = load_dataset(DATASET_FOLDER + \"/*\" + '-val.hdf5')\n",
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileModel(model,optimizer='sgd', lr=0.001):\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr, momentum=0.0)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the MLP model (for GridSearchCV)\n",
    "def create_model(optimizer='sgd', dense_layers=4, hidden_units=2, learning_rate = 0.001, dropout_rate=0, activation='relu'):\n",
    "    model = Sequential(name  = \"mlp\")\n",
    "    model.add(Dense(hidden_units, input_shape=(21,), activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for layer in range(dense_layers):\n",
    "        model.add(Dense(hidden_units, activation='relu', name='hidden-fc' + str(layer)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid', name='fc2'))\n",
    "    compileModel(model, optimizer,learning_rate)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KerasClassifier based on the create_model function\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n",
    "\n",
    "PATIENCE = 10\n",
    "k=2 # number of folds for cross-validation\n",
    "\n",
    "# Define the hyperparameters to tune and their possible values\n",
    "param_grid = {\n",
    "    'learning_rate' : [0.001,0.01],\n",
    "    'optimizer' : ['sgd','adam'],\n",
    "    'hidden_units' : [16,32],\n",
    "    'dropout_rate': [0,0.9]\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=k)\n",
    "\n",
    "### Add early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE, restore_best_weights=True)\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks= [early_stopping])\n",
    "stop_time = time.time()\n",
    "\n",
    "# Total training time\n",
    "print(\"Total training time (sec): \", stop_time-start_time)\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best cross-validated accuracy: {:.2f}\".format(grid_result.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test accuracy of the best model: {:.2f}\".format(test_accuracy))\n",
    "\n",
    "# Save the best model   \n",
    "best_model.model.save('best_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NIADML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
